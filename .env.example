# =============================================================================
# BENCHMARK CONFIGURATION
# =============================================================================
# Copiez ce fichier en .env et ajustez les valeurs selon votre environnement

# -----------------------------------------------------------------------------
# GENERAL
# -----------------------------------------------------------------------------
# Dossier contenant les fichiers CSV à traiter
DATA_DIR=data

# Dossier de sortie pour les fichiers Parquet
OUTPUT_DIR=benchmark_outputs

# Dossier pour les métriques JSON
METRICS_DIR=benchmark_metrics

# Intervalle de collecte des métriques (en secondes)
SAMPLE_INTERVAL=0.5

# Temps de pause entre chaque benchmark (en secondes)
COOLDOWN_TIME=5

# -----------------------------------------------------------------------------
# SPARK CONFIGURATION
# -----------------------------------------------------------------------------
# Mémoire allouée au driver Spark
SPARK_DRIVER_MEMORY=8g

# Mémoire allouée aux executors Spark
SPARK_EXECUTOR_MEMORY=8g

# Nombre de partitions pour le shuffle
SPARK_SHUFFLE_PARTITIONS=12

# Parallélisme par défaut
SPARK_PARALLELISM=12

# Mode master (local[*] = tous les cores, local[4] = 4 cores)
SPARK_MASTER=local[*]

# Chemin vers Hadoop (Windows uniquement, laisser vide sur Linux/Mac)
HADOOP_HOME=C:\hadoop

# -----------------------------------------------------------------------------
# LIBRARIES TO BENCHMARK
# -----------------------------------------------------------------------------
# Mettre "true" ou "false" pour activer/désactiver chaque librairie
BENCH_PANDAS=true
BENCH_POLARS=true
BENCH_DUCKDB=true
BENCH_PYSPARK=true
